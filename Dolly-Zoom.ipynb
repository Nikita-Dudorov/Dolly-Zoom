{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ef0400-6672-4117-9652-c2975b288771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de502e9-f775-441b-b9b8-da3eb4cc8dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Folder with photos of an object taken from different distances\n",
    "image_dir = 'data/photos/series_6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c6052b-be26-42d7-89cc-fd2aaee5c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Instead you can extract frames from a video\n",
    "EXTRACT_FROM_VIDEO = False\n",
    "if(EXTRACT_FROM_VIDEO):\n",
    "    from Video_utils import extract_video_frames\n",
    "    video_path = 'data/videos/backpack_lr.mp4'\n",
    "    extract_dir = 'extract_video'\n",
    "    save_each = 5\n",
    "    extract_video_frames(video_path, extract_dir, save_each)\n",
    "    image_dir = extract_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532ac206-4c3a-453d-a3be-f1e54c370d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "### To accelerate computations and avoid RAM overflow you may want to compress your images\n",
    "### But image compression makes the feature detection more difficult and the algortihm may fail\n",
    "COMPRESS = False\n",
    "if(COMPRESS):\n",
    "    from Video_utils import compress_images\n",
    "    compressed_dir = image_dir+'_compressed'\n",
    "    compress_images(image_dir, compressed_dir, factor = 0.5)\n",
    "    image_dir = compressed_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343bcff4-5481-418e-960e-6513410462e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Photos must be sorted by distance they were taken from\n",
    "image_paths = [os.path.join(image_dir, im_name) for im_name in os.listdir(image_dir)]\n",
    "image_paths.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa662e8e-d203-4792-9844-0c9c025a5c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### You may want to take just a part of the photos - the closest ones \n",
    "### as numerical zoom can crash if the object is too far\n",
    "image_paths = image_paths[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793e73d0-5e6e-4f80-a07d-b1ea983140bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Choose bounds of the object which will keep fixed size \n",
    "### in dolly-zoom effect\n",
    "base_image = io.imread(image_paths[0])\n",
    "h0, w0, c = base_image.shape\n",
    "base_object_bounds = np.array([[0,0],[w0,h0]])\n",
    "\n",
    "@interact(x1=(0,w0,10), y1=(0,h0,10), x2=(0,w0,10), y2=(0,h0,10))\n",
    "def adjust_base_object_position(x1=0, y1=0, x2=w0, y2=h0):\n",
    "    h = y2-y1 if y2>y1 else 0\n",
    "    w = x2-x1 if x2>x1 else 0\n",
    "    \n",
    "    fig,ax=plt.subplots()\n",
    "    rect = patches.Rectangle((x1, y1), w, h, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    ax.imshow(base_image)\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    base_object_bounds[0] = np.array([x1,y1])\n",
    "    base_object_bounds[1] = np.array([x2,y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb7bf92-c833-4cc0-aeae-f441978401ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_object_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc589564-8418-4aa7-bf10-7baee178a739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DollyZoom_utils import make_frames\n",
    "from Video_utils import make_video, make_gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d334ddb1-ac94-49ab-aa0b-2a28d311300d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frame_dir = \"video_frames\"\n",
    "make_frames(image_paths, base_object_bounds, frame_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b3f8e7-f325-4270-ac82-bb27cce89823",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = \"video.avi\"\n",
    "make_video(frame_dir, video_name, fps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f209fc58-9bd2-4df3-915d-8dc988bd3ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gif_name = \"video.gif\"\n",
    "# make_gif(frame_dir, gif_name, fps=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
